{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Set Up\n",
    "Read the dataset into a Dataframe called jeopardy using Pandas.\n",
    "\n",
    "Print out the first 5 rows of jeopardy.\n",
    "\n",
    "Print out the columns of jeopardy using jeopardy.columns.\n",
    "\n",
    "Some of the column names have spaces in front.\n",
    "\n",
    "Remove the spaces in each item in jeopardy.columns.\n",
    "\n",
    "Assign the result back to jeopardy.columns to fix the column names in jeopardy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', 'Air Date', 'Round', 'Category', 'Value', 'Question',\n",
       "       'Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "jeopardy = pd.read_csv('jeopardy.csv')\n",
    "jeopardy = jeopardy.rename(columns=lambda x: x.strip())\n",
    "\n",
    "#print (jeopardy.head(5))\n",
    "jeopardy.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalising Text\n",
    "Write a function to normalize questions and answers. It should:\n",
    "\n",
    "Take in a string.\n",
    "\n",
    "    Convert the string to lowercase.\n",
    "    \n",
    "    Remove all punctuation in the string.\n",
    "    \n",
    "    Return the string.\n",
    "    \n",
    "Normalize the Question column.\n",
    "\n",
    "    Use the Pandas apply method to apply the function to each item in the Question column.\n",
    "    \n",
    "    Assign the result to the clean_question column.\n",
    "    \n",
    "Normalize the Answer column.\n",
    "\n",
    "    Use the Pandas apply method to apply the function to each item in the Answer column.\n",
    "    \n",
    "    Assign the result to the clean_answer column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normie(text):\n",
    "    # convert string to lowercase\n",
    "    text = text.lower()\n",
    "    # remove all punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n",
    "\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normie)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Normalising Non-text\n",
    "\n",
    "Write a function to normalize dollar values. It should:\n",
    "\n",
    "    Take in a string.\n",
    "    \n",
    "    Remove any punctuation in the string.\n",
    "    \n",
    "    Convert the string to an integer.\n",
    "    \n",
    "    If the conversion has an error, assign 0 instead.\n",
    "    \n",
    "    Return the integer.\n",
    "    \n",
    "Normalize the Value column.\n",
    "\n",
    "    Use the Pandas apply method to apply the function to each item in the Value column.\n",
    "    \n",
    "    Assign the result to the clean_value column.\n",
    "    \n",
    "Use the pandas.to_datetime function to convert the Air Date column to a datetime column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normint(val):\n",
    "    # remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        val = val.replace(punctuation, '')\n",
    "    # convert to integer and if error, assign zero:\n",
    "    try: \n",
    "        val = int(val)\n",
    "    except: \n",
    "        val = 0\n",
    "    if val == 'none':\n",
    "        val = 0\n",
    "    return val\n",
    "\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(normint)\n",
    "\n",
    "# convert date to date time format\n",
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Answers in Questions\n",
    "\n",
    "Find out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "\n",
    "    How often the answer is deducible from the question.\n",
    "    How often new questions are repeats of older questions.\n",
    "\n",
    "Write a function that takes in a row in jeopardy, as a Series.\n",
    "\n",
    "It should:\n",
    "\n",
    "    Split the clean_answer column on the space character (), and assign to the variable split_answer.\n",
    "\n",
    "    Split the clean_question column on the space character (), and assign to the variable split_question.\n",
    "    \n",
    "    Create a variable called match_count, and set it to 0.\n",
    "\n",
    "    If the is in split_answer, remove it using the remove method on lists. The is commonly found in answers and questions, but doesn't have any meaningful use in finding the answer.\n",
    "    \n",
    "    If the length of split_answer is 0, return 0. This prevents a division by zero error later.\n",
    "    \n",
    "    Loop through each item in split_answer, and see if it occurs in split_question. If it does, add 1 to match_count.\n",
    "    \n",
    "    Divide match_count by the length of split_answer, and return the result.\n",
    "\n",
    "Count how many times terms in clean_answer occur in clean_question.\n",
    "\n",
    "    Use the Pandas apply method on Dataframes to apply the function to each row in jeopardy.\n",
    "    \n",
    "    Pass the axis=1 argument to apply the function across each row.\n",
    "    \n",
    "    Assign the result to the answer_in_question column.\n",
    "    \n",
    "Find the mean of the answer_in_question column using the mean method on Series.\n",
    "\n",
    "Write up a markdown cell with a short explanation of how finding this mean might influence your studying strategy for Jeopardy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.058206961574629956"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def deducible(row):\n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question= row['clean_question'].split()\n",
    "    match_count = 0\n",
    "    for word in split_answer:\n",
    "        if word == \"the\":\n",
    "            split_answer.remove(word)\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        for item in split_answer:\n",
    "            if item in split_question:\n",
    "                match_count += 1\n",
    "        return (match_count/len(split_answer))\n",
    "answer_in_question = jeopardy.apply(deducible, axis = 1)        \n",
    "\n",
    "\n",
    "meancounts = answer_in_question.mean()\n",
    "meancounts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean shows that there is the answer only coincides with the question only about once in 20 times. Hence, it's not entirely useful to use this \"deducible\" method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recycle Questions\n",
    "\n",
    "This investigates how often new questions are repeats of older ones.\n",
    "\n",
    "Sort jeopardy in order of ascending air date.\n",
    "\n",
    "Maintain a set called terms_used that will be empty initially.\n",
    "\n",
    "Iterate through each row of jeopardy (using iterrows)\n",
    "\n",
    "Split clean_question into words, remove any word shorter than 6 characters, and check if each word occurs in terms_used.\n",
    "\n",
    "If it does, increment a counter.\n",
    "\n",
    "Add each word to terms_used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy = jeopardy.sort_values(by='Air Date',ascending=True)\n",
    "\n",
    "terms_used = []\n",
    "question_overlap =[]\n",
    "\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_question = row['clean_question'].split()\n",
    "    for word in split_question:\n",
    "        if len(word) < 6:\n",
    "            split_question.remove(word)\n",
    "    match_count = 0\n",
    "    for word in split_question:\n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        terms_used.append(word)\n",
    "    if len(split_question) > 0:\n",
    "        match_count = match_count/len(split_question)\n",
    "    question_overlap.append(match_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.798436884793\n"
     ]
    }
   ],
   "source": [
    "jeopardy['question_overlap'] = question_overlap\n",
    "meanques = jeopardy['question_overlap'].mean()\n",
    "print (meanques)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out whcih terms correspond to high-value questions using chi-square test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low vs High value Questions\n",
    "\n",
    "Find out which questions to study such that it pertain to high value questions instead of low value questions. In order to get this, find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values. Doing this for all of the words would take a very long time, so we'll just do it for a small sample now.\n",
    "\n",
    "Create a function that takes in a row from a Dataframe, and:\n",
    "\n",
    "    If the clean_value column is greater than 800, assign 1 to value.\n",
    "\n",
    "    Otherwise, assign 0 to value.\n",
    "\n",
    "    Return value.\n",
    "    \n",
    "Use the Pandas apply method on Dataframes to apply the function to each row in jeopardy.\n",
    "\n",
    "Pass the axis=1 argument to apply the function across each row.\n",
    "\n",
    "Assign the result to the high_value column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Show Number                  int64\n",
       "Air Date            datetime64[ns]\n",
       "Round                       object\n",
       "Category                    object\n",
       "Value                       object\n",
       "Question                    object\n",
       "Answer                      object\n",
       "clean_question              object\n",
       "clean_answer                object\n",
       "clean_value                  int64\n",
       "question_overlap           float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jeopardy.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def highlow(row):\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    return value\n",
    "\n",
    "jeopardy['high_value'] = jeopardy.apply(highlow, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that takes in a word, and:\n",
    "\n",
    "    Assigns 0 to low_count.\n",
    "    Assigns 0 to high_count.\n",
    "    Loops through each row in jeopardy using the iterrows method.\n",
    "    Split the clean_question column on the space character ().\n",
    "    If the word is in the split question:\n",
    "        If the high_value column is 1, add 1 to high_count.\n",
    "        Else, add 1 to low_count.\n",
    "    \n",
    "    Returns high_count and low_count. You can return multiple values by separating them with a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def highlowcounts(word):\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    for index, row in jeopardy.iterrows():\n",
    "        splitwords = row['clean_question'].split()\n",
    "        if word in splitwords:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else: \n",
    "                low_count += 1\n",
    "    return high_count, low_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty list called observed_expected.\n",
    "\n",
    "Convert terms_used into a list using the list function, and assign the first 5 elements to comparison_terms.\n",
    "\n",
    "Loop through each term in comparison_terms, and:\n",
    "\n",
    "    Run the function on the term to get the high value and low value counts.\n",
    "    Append the result of running the function (which will be a list) to observed_expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observed_expected = []\n",
    "\n",
    "terms_usedlist = list(terms_used)\n",
    "comparison_terms = terms_usedlist[0:5]\n",
    "\n",
    "for term in comparison_terms:\n",
    "    result = highlowcounts(term)\n",
    "    observed_expected.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 3), (68, 181), (781, 1754), (1209, 2962), (2324, 5491)]\n"
     ]
    }
   ],
   "source": [
    "print (observed_expected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying the chi-squared test\n",
    "\n",
    "With the observed counts for a few terms, compute the expected counts and the chi-squared value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the number of rows in jeopardy where high_value is 1, and assign to high_value_count.\n",
    "\n",
    "Find the number of rows in jeopardy where high_value is 0, and assign to low_value_count.\n",
    "\n",
    "Create an empty list called chi_squared.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_value_count = jeopardy[jeopardy['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy[jeopardy['high_value'] == 0].shape[0]\n",
    "\n",
    "chi_squared = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through each list in observed_expected.\n",
    "\n",
    "    Add up both items in the list (high and low counts) to get the total count, and assign to total.\n",
    "    Divide total by the number of rows in jeopardy to get the proportion across the dataset. Assign to total_prop.\n",
    "    Multiply total_prop by high_value_count to get the expected term count for high value rows.\n",
    "    Multiply total_prop by low_value_count to get the expected term count for low value rows.\n",
    "    Use the scipy.stats.chisquare function to compute the chi-squared value and p-value given the expected and observed counts.\n",
    "    Append the results to chi_squared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.2058885383806519, 0.27214791766902047], [0.22592591114717697, 0.63456129826261032], [5.6620493537229537, 0.017335855359660587], [0.20162796200547214, 0.65340999849142001], [4.3444466443049095, 0.037129831143466852], [1.2058885383806519, 0.27214791766902047], [0.22592591114717697, 0.63456129826261032], [5.6620493537229537, 0.017335855359660587], [0.20162796200547214, 0.65340999849142001], [4.3444466443049095, 0.037129831143466852]]\n"
     ]
    }
   ],
   "source": [
    "for elem in observed_expected:\n",
    "    total = sum(elem)\n",
    "    total_prop = total/ (jeopardy.shape[0])\n",
    "    expectedhigh = total_prop * high_value_count\n",
    "    expectedlow = total_prop * low_value_count\n",
    "    expectedvals = [expectedhigh, expectedlow]\n",
    "    chisqvalue, pvalue = chisquare(elem, expectedvals)\n",
    "    chi_squared.append([chisqvalue, pvalue])\n",
    "\n",
    "print (chi_squared)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
